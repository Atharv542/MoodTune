import os 
import numpy as np
import tensorflow as tf 
from tensorflow import keras
from tensorflow.keras import Model
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import (Input, Dense, Dropout, GlobalAveragePooling2D, RandomFlip,RandomRotation, RandomZoom, RandomTranslation)
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input
from tensorflow.keras.callbacks import (ModelCheckpoint, EarlyStopping, ReduceLROnPlateau)
from tensorflow.keras.utils import image_dataset_from_directory
import matplotlib.pyplot as plt 
from sklearn.metrics import confusion_matrix,classification_report
import itertools


data_dir= "train"
IMG_SIZE=(224,224)
Batch_Size=32
SEED=42
train_ds= image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset='training',
    batch_size=Batch_Size,
    image_size=IMG_SIZE,
    seed= SEED
)
val_ds= image_dataset_from_directory(
    data_dir,
    validation_split=0.2,
    subset='validation',
    batch_size=Batch_Size,
    image_size=IMG_SIZE,
    seed= SEED
)
class_names= train_ds.class_names
print("Classes:",class_names)


AUTOTUNE= tf.data.AUTOTUNE
train_ds= train_ds.shuffle(1000).prefetch(AUTOTUNE)
val_ds= val_ds.prefetch(AUTOTUNE)


data_augmentation= tf.keras.Sequential([
    RandomFlip('horizontal'),
    RandomRotation(0.07),
    RandomZoom(0.1),
    RandomTranslation(0.05,0.05),
],name="data_augmentation")


base_model= EfficientNetB0(include_top=False,weights='imagenet',input_shape=(IMG_SIZE[0],IMG_SIZE[1],3))
base_model.trainable= False

inputs= Input(shape=(IMG_SIZE[0],IMG_SIZE[1],3))
x=data_augmentation(inputs)
x=preprocess_input(x)
x=base_model(x,training=False)
x=GlobalAveragePooling2D()(x)
x=Dropout(0.35)(x)
x=Dense(256,activation='relu')(x)
x=Dropout(0.3)(x)
outputs=Dense(len(class_names),activation='softmax')(x)

model=Model(inputs,outputs)
model.summary()


model.compile(optimizer=tf.keras.optimizers.Adam(3e-4),loss='sparse_categorical_crossentropy',metrics=['accuracy'])


checkpoint_cb = ModelCheckpoint(
    "best_effnet.h5", save_best_only=True,
    monitor="val_accuracy", mode="max"
)

earlystop_cb = EarlyStopping(
    monitor="val_loss", patience=6,
    restore_best_weights=True
)

reduce_lr = ReduceLROnPlateau(
    monitor="val_loss", factor=0.5,
    patience=3, min_lr=1e-6
)




